{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e49fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 15:26:09.304274: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-24 15:26:10.123818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.lite.python import interpreter as interpreter_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029dc946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model_path=\"t.tflite\"\n",
    "model_input_shape=(608,608)\n",
    "interpreter = interpreter_wrapper.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "#model_format = 'TFLITE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ae7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ehsan input shape correctness\n",
    "input_details = interpreter.get_input_details()\n",
    "input_shape = input_details[0]['shape']\n",
    "input_shape[1] = model_input_shape[0]\n",
    "input_shape[2] = model_input_shape[1]\n",
    "interpreter.resize_tensor_input(0, input_shape)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c241fffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TensorFlow Lite model to a Keras .h5 model\n",
    "input_tensors = interpreter.get_input_details()\n",
    "output_tensors = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694c5230",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the input and output shapes of the Keras model\n",
    "input_shape = (608, 608, 3)\n",
    "output_shape = [(1, 1, 1, 255), (1, 19, 19, 255), (1, 1, 1, 255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba415dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec(shape=input_shape[i], dtype=tf.float32) for i in range(len(input_shape))])\n",
    "def tflite_inference(*inputs):\n",
    "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], inputs[0])\n",
    "    interpreter.invoke()\n",
    "    return tuple(interpreter.get_tensor(output_tensors[i]['index']) for i in range(len(output_tensors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdd1732f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'StatefulPartitionedCall:0', 'index': 343, 'shape': array([  1,   1,   1, 255], dtype=int32), 'shape_signature': array([ -1,  -1,  -1, 255], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 301, 'shape': array([  1,  19,  19, 255], dtype=int32), 'shape_signature': array([ -1,  -1,  -1, 255], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 322, 'shape': array([  1,   1,   1, 255], dtype=int32), 'shape_signature': array([ -1,  -1,  -1, 255], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[343, 301, 322]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_tensors)\n",
    "[output_tensors[i]['index'] for i in range(len(output_tensors))]\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e7b37",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Convert the TensorFlow Lite model to a Keras .h5 model\n",
    "def m():\n",
    "    output_tensors = interpreter.get_output_details()\n",
    "    keras_model = tf.keras.models.Sequential([tf.keras.layers.Lambda(tflite_inference, input_shape=input_shape, output_shape=output_shape)])\n",
    "    keras_model.save(\"t.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    m()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
